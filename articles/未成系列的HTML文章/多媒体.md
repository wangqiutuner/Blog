# 前端多媒体

## 一、音视频基础

### 1、视频

#### 基本概念

**码率：** 比特率（bit/s或bps），表示每秒传送的比特数，又称数据信号速率
**帧率：** 视频帧率，可以理解为图形处理器每秒钟能够刷新多少次
**压缩率：** 经过压缩后文件的大小 / 原始文件的大小 * 100% = 压缩率

> 压缩率一般是越小越好，但是压的越小，解压时间越长
>
> **常见编码格式压缩率**
> 举例：视频文件3840x2160.yuv（大小：3.6GB，分辨率：3840x2160 4k 帧率25fps，码率：10Mbps），使用H.265编码方式压缩后文件大小15MB
>
> H.265编码方式下，压缩文件：15MB，压缩率为: 15 / 3600 * 100% ≈ 0.42%
> H.264编码方式下，压缩率是H.265的 1/2

#### 容器格式

**视频格式：** 我们平时所说的视频格式主要分为两种，一个是封装格式，另一个是编解码格式。

**封装格式：**​ 视频封装格式就是将已经编码处理的视频数据、音频数据、字幕数据等按照一定的方式放到一个文件中。例如：MP4、AVI、WebM等等。

**MP4：** 又称MPEG-4第14部分（MPEG-4 Part 14），由国际标准化组织（ISO）和国际电工委员会（IEC）下属的”动态图像专家组“（Moving Picture Experts Group，即MPEG）制定。

**AVI：** 音频视频交错格式，由微软在1992年11月推出的一种多媒体文件格式，用于对抗苹果Quicktime的技术。

**WebM：** 由Google提出，是一种专为Web设计的开放，免版税的媒体文件格式。WebM 影片格式其实是以 Matroska（即 MKV）容器格式为基础开发的新容器格式，里面包括了VP8影片轨和 Ogg Vorbis 音轨。

**MOV：** MOV视频容器是Apple Quicktime中经常使用的一种常见的多媒体格式，它使用Apple Computer开发的专有压缩算法来保存电影和其他视频文件。

**FLV：** FLV（Flash Video）是现在非常流行的流媒体格式，由于其视频文件体积轻巧、封装播放简单等特点，使其很适合在网络上进行应用，现各视频网站大多使用的是FLV格式。

#### 编码格式

**MPEG系列：** MPEG-1第二部分主要使用在VCD上，有些在线视频也使用这种格式。MPEG-2第二部分等同于H.262，使用在DVD、SVCD和大多数数字视频广播系统和有线分布系统(cable distribution systems)中。MPEG-4第二部分标准可以使用在网络传输、广播和媒体存储上。

**H.264：** 又称MPEG-4 Part 10，高级视频编码或AVC。是由ITU-T视频编码专家组（VCEG）和ISO/IEC动态图像专家组（MPEG）联合组成的联合视频组（JVT，Joint Video Team）提出的高度压缩数字视频编解码器标准。

**H.265：** 又称MPEG-H Part2或HEVC，由视频编码联合协作小组（JCT-VC）开发，旨在在有限带宽下传输更高质量的网络视频，与H.264相比，同样的视觉质量的视频只占用一半的空间，仅需原先的一半带宽即可播放相同质量的视频，或者具有相同文件大小和比特率的视频可能看起来更好。

**H.266：** 也被称为多功能视频编码（Versatile Video Coding，简称 VVC），是 H.265 的继任者。VVC 对 8K 超高清、屏幕、高动态和 360 度全景视频等新的视频类型以及自适应带宽和分辨率的流媒体和实时通信等应用有了更好的支持。

**VP9：** VP9是一个由Google开发的开放格式、无使用授权费的视频压缩标准。VP9支持从低比特率压缩到高质量超高清的所有Web和移动用例，并额外支持10/12位编码和HDR。

**AV1：** 是由AOM（Alliance for Open Media，开放媒体联盟）制定的一个开源、免版权费的视频编码格式，目标是解决H265昂贵的专利费用和复杂的专利授权问题并成为新一代领先的免版权费的编码标准。此外，AV1是google制定的VP9标准的继任者，也是H265强有力的竞争者。

<table summary="常用编解码器">
    <caption>常用编解码器</caption>
    <tr>
        <th>编解码器简称</th>
        <th>编解码器全称</th>
        <th>容器支持</th>
    </tr>
    <tr>
        <td>MPEG-1</td>
        <td>MPEG-1 Part 2 Visual</td>
        <td>MPEG、QuickTime</td>
    </tr>
    <tr>
        <td>MPEG-2</td>
        <td>MPEG-2 Part 2 Visual</td>
        <td>MP4、MPEG、QuickTime</td>
    </tr>
    <tr>
        <td>AVC(H.264)</td>
        <td>Advanced Video Coding（高级视频编码器）</td>
        <td>3GP、MP4</td>
    </tr>
    <tr>
        <td>HEVC(H.265)</td>
        <td>Advanced Video Coding（高级视频编码器）</td>
        <td>3GP、MP4</td>
    </tr>
    <tr>
        <td>VP9</td>
        <td>Video Processor 9</td>
        <td>MP4、Ogg、WebM</td>
    </tr>
    <tr>
        <td>AC1</td>
        <td>AOMedia Video 1</td>
        <td>MP4、WebM</td>
    </tr>
</table>

## 二、 直播技术

### 1、推拉流

![视频](./img/img_1.png)

1. 经过输出设备得到原始的采样数据--视频数据和音频数据
2. 使用硬编码（对应系统的API）或软编码（FFMpeg等）来编码压缩音视频数据
3. 然后根据不同的封装格式（如FLV、TS、MPEG-TS）进行封装打包
4. 通过不同的传输协议（如RTMP、RTP等）将流上传到服务器
5. 服务器进行节点分发（CDN）
6. 用户侧通过不同的传输协议（如RTMP、HLS、HTTP-FLV等）获取流数据
7. 同步骤3、2反向解封装和解码音视频数据
8. 进行渲染播放

### 2、流媒体协议

**RTMP：** RTMP是Real Time Messaging Protocol（实时消息传输协议）的首字母缩写，在合适的传输协议（如TCP）的基础上设计用于多路复用和包装多媒体传输流（如音频、视频和交互式内容）的应用层协议，主要用于Flash，一般使用flv格式的媒体流。

**RTP/RTCP/RRTSP：** RTP和RTCP都是基于UDP，用作数据传输。RTSP是基于TCP的，属于应用层协议，种双向实时数据传输协议，它允许客户端向服务端发送请求，如回放、快进、倒退等操作。

![RTP](./img/img_2.webp)

**HTTP-FLV：** FLV是Adobe公司提出一种视频格式，由于协议简单、传输体积小而被广泛采用，而常见的HTTP-FLV流媒体协议是通过HTTP协议将FLV封装过的视频内容、音频内容流式传输到端上，从而实现直播播放诉求。

**HLS：** HLS (HTTP Live Streaming) 是 Apple 提出的直播流协议，它诞生于2009年，一个意在颠覆流媒体产业的新协议。它的工作原理是把一段视频流切分成一个个的小块，并基于 HTTP 的文件来下载。主要用于直播回放，缺点是延迟比较大，通常不低于10s。

**DASH：** 基于HTTP的动态自适应流，也称MPEG-DASH，是一种自适应比特率流技术，使高质量流媒体可以通过传统的HTTP网络服务器以互联网传递。类似苹果公司的HTTP Live Streaming（HLS）方案。

![RTP](./img/img_3.webp)

## 三、 播放器

### 1、拉流

video元素本身支持h264编码的mp4、vp8编码的webm、theora编码的ogg视频格式。浏览器内部处理拉流逻辑。
对于像flv格式的视频流数据，我们需要自行拉取数据。

```javascript
fetch(this.url, {
  method: "GET"
}).then(resp => {
  const { status, statusText } = resp;
  resp.body.getReader().then(result => {
    let { value, done } = result;
    value = new Uint8Array(value ? value : 0);
    this.data = concat(this.data, value);
    if (done) {
      this.done = true;
    } else if (this.data.length < this.chunkSize) {
      // ...,
    }
  });
});
```

### 2、解封装

mux为Multiplex的缩写，封装之意，而 demux 即为解封。
通过 muxing（混流），可以将视频流、音频流甚至是字幕流合并到一个单独的文件中，作为一个信号进行传输。等传输完毕，就可以通过 demux（分离） 将里面的视频、音频或字幕分解出来各自进行解码和播放。

![解封装](./img/img_4.png)

### 3、解码

SPS、PPS、IBP帧等等

### 4、渲染

渲染，指的是将解码后的数据，在 pc 硬件上（显示器、扬声器）进行播放。负责渲染的模块我们称之为渲染器(Render)。

![渲染](./img/img_5.png)

**MSE：** 媒体源扩展 API（MSE）提供了实现无插件且基于 Web 的流媒体的功能。使用 MSE，媒体串流能够通过 JavaScript 创建，并且能通过使用 `<audio>` 和 `<video>` 元素进行播放。
